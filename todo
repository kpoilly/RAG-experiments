### ✅ To-Do List du Projet RAG "Boilerplate"

---

#### **Phase 1 : MVP**

*Objectif : Transformer le projet en un outil fonctionnel  à utiliser en local, avec une gestion simple des documents et un comportement robuste face aux erreurs.*

-   **Configuration dynamique via l'UI :**
    -   Modifier l'endpoint /chat pour accepter des paramètres optionnels (strict_mode, reranker_threshold).
    -   Permettre à l'UI Streamlit de surcharger ces paramètres pour la session en cours.

-   **Mieux gérer l'historique :**
    - Implémenter une stratégie de fenêtre glissante ("sliding window") pour ne conserver que les N derniers échanges et éviter de dépasser la limite de contexte du LLM.

-   **Améliorer la Résilience du Pipeline :**
    -   Mettre en place une dégradation gracieuse : si un composant optionnel (ex: query_expansion, reranker) échoue, l'application doit continuer à fonctionner sans lui et logger un avertissement.
    -   **Gestion dynamique du contexte LLM :**
        -   Ajouter un endpoint /models au llm-gateway pour exposer les capacités des modèles (ex: max_tokens).
        -   Au démarrage du rag-core, appeler cet endpoint pour récupérer dynamiquement la context_window du LLM configuré.

-   **Refactorisation et "Code Polishing" :**
    -   Centraliser tous les hyperparamètres du RAG (chunk_size, k, threshold...) dans le fichier config.py.
    -   Découper les fonctions monolithiques (orchestrate_rag_flow) en plus petites fonctions testables.

---

#### **Phase 2 : MLOps & Fondations de Production**

*Objectif : Mettre en place l'outillage pour garantir la qualité, la sécurité, l'automatisation et l'observabilité du projet.*

-   **Mettre en place les Tests (`pytest`) :**
    -   Écrire les **tests unitaires** pour les fonctions critiques (utils, config, parsing des prompts).
    -   Écrire un **test d'intégration** simple pour l'endpoint `/health` et pour vérifier que l'agent route bien vers le bon "Tool".

-   **Construire la Pipeline de CI/CD (GitHub Actions) :**
    -   Mettre en place le workflow de **CI** qui exécute `lint` et les `tests` en parallèle pour chaque service.
    -   Préparer un squelette de workflow de **CD** pour le déploiement.

-   **Architecture Multi-Tenant et Sécurité :**
    -   Ajouter la validation du type de fichier avec `python-magic`.
    -   Gestion des Utilisateurs : Mettre en place un système d'authentification de base (ex: JWT) pour identifier les utilisateurs.
    -   Sécuriser les APIs : Implémenter une authentification par token sur les endpoints (/chat, /ingest).
    -   Isolation des Données : Rendre le collection_name et le namespace dynamiques, basés sur l'ID de l'utilisateur, pour garantir la confidentialité des documents.
    -   Gestion des Quotas (BYOK - Bring Your Own Key) :
        -   Permettre aux utilisateurs de stocker leur propre clé API de manière sécurisée (chiffrée en base de données).
        -   Modifier le llm-gateway pour qu'il transmette la clé de l'utilisateur au Proxy LiteLLM pour chaque requête.
        -   Ajouter une logique de limitation d'usage (ex: nombre de documents, nombre de requêtes par mois) pour chaque utilisateur.

---

#### **Phase 3 : Monitoring, Évaluation et Optimisation du RAG**

*Objectif : Mesurer objectivement la performance du RAG et l'améliorer sur la base de données concrètes.*

-   **Mettre en place l'Évaluation (`RAGAs`) et l'Observabilité (`LangSmith`) :**
    -   Intégrer RAGAS (Golden Dataset, évaluations).
    -   Stratégie d'évaluations (schedulées ?)

-   **Monitoring et Analyse de la Latence :**
    -   Mettre en place **Prometheus/Grafana/Loki**.

---

### **Phase 4 : Architecture de Déploiement et Cloud :**

*Objectif : Préparer et maîtriser le déploiement de l'application sur une infrastructure cloud scalable.*

-   **Passage au Stockage Cloud :**
    -   Remplacer le volume local /data par un bucket de stockage objet (ex: Cloudflare R2, Google Cloud Storage).
    -   Mettre en placeodifier l'UI et l'ingestion pour uploader/lire les fichiers depuis ce bucket.

-   **Héberger la Base de Données :**
    -   Migrer la base de données PostgreSQL vers un service managé (ex: Supabase, Cloud SQL).

-   **Point d'Entrée Réseau (Reverse Proxy) :**
    -   Intégrer Nginx dans docker-compose comme point d'entrée unique.
    -   Configurer Nginx pour la terminaison SSL/TLS (HTTPS) et le routage vers le service UI.

-   **Préparation pour Kubernetes :**
    -   Installer et configurer **Kind** ou **Minikube**.
    -   Commencer à écrire les manifestes Kubernetes, en utilisant un Ingress Controller (Nginx) comme équivalent du reverse proxy.



#### **Phase 5 : Déploiement Cloud-Native sur Kubernetes**

*Objectif : Maîtriser le déploiement, la gestion d'environnements et l'automatisation de bout en bout.*


-   **Écrire les Manifestes complets :**
    -   Créer les fichiers `Deployment`, `Service`, `ConfigMap`, `Secret` pour chaque microservice.

-   **Gérer les Environnements (`staging` vs. `production`) :**
    -   Mettre en place **Kustomize** pour gérer les variations de configuration.

-   **Mettre à jour le Pipeline de CD (Déploiement Continu) :**
    -   Créer un workflow GitHub Actions pour le **Déploiement Continu**.
    -   Automatiser le déploiement sur **staging**.
    -   Mettre en place une **approbation manuelle** pour le déploiement en **production**.

-   **Porter ça sur GCP**

---

#### **Phase 6 : Expansion des Capacités de l'Agent**

*Objectif : Enrichir l'agent avec de nouvelles compétences et sources d'information.*

-   **Ajouter des Outils Externes :**
    -   Intégrer un outil **Web Search** (ex: `Tavily`).

-   **Diversifier les Sources de Données :**
    -   Ajouter l'ingestion depuis des URLs, Google Drive, Slack...
    -   gestion des images (**OCR** pour extraire le texte des images, description d'image etc.)

-   **(Avancé) Implémenter le Mode Haute Précision :**
    -   Ajouter la logique de **RAG-Fusion** comme une option configurable.
