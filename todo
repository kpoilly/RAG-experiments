### ✅ To-Do List du Projet RAG "Boilerplate"

---

#### **Phase 1 : MVP**

*Objectif : Transformer le projet en un outil fonctionnel  à utiliser en local, avec une gestion simple des documents et un comportement robuste face aux erreurs.*

-   **Ajouter les séparateurs pour les splitters :**
    -   Parents: \n# \n## \n\n\n
    -   Childs: \n\n \n### \n " "
    -   Potentiellement ajuster taille des chunks.
-   **Multi-staging sur les dockerfiles :**
    -   Utiliser uv et pyproject.toml
-   **Gestion dynamique du contexte LLM :**
    -   Ajouter un endpoint /models au llm-gateway pour exposer les capacités des modèles (ex: max_tokens).
    -   Au démarrage du rag-core, appeler cet endpoint pour récupérer dynamiquement la context_window du LLM configuré.

---

#### **Phase 2 : Monitoring et Évaluation**

*Objectif : Mesurer objectivement la performance du RAG et l'améliorer sur la base de données concrètes.*

-   **Mettre en place l'Évaluation (`RAGAs`) et l'Observabilité (`LangSmith`) :**
    -   Intégrer RAGAS (Golden Dataset, évaluations).
    -   Stratégie d'évaluations (schedulées ?)

-   **Monitoring et Analyse de la Latence :**
    -   Mettre en place **Prometheus/Grafana/Loki**.

---

#### **Phase 3 : MLOps & Architecture API-First**

*Objectif : Mettre en place l'outillage pour garantir la qualité, la sécurité, l'automatisation et construire une API robuste et sécurisée.*

-   **Passer à une Architecture "API-First" :**
    -   Refactoriser l'endpoint /ingest pour accepter l'upload de fichiers, des URLs... depuis l'API.

-   **Sécurité :**
    -   Ajouter la validation du type de fichier avec `python-magic`.
    -   Gestion des Utilisateurs : Mettre en place un système d'authentification de base (ex: JWT) pour identifier les utilisateurs.
    -   Sécuriser les APIs : Implémenter une authentification par token sur les endpoints (/chat, /ingest).
    -   Isolation des Données : Rendre le collection_name et le namespace dynamiques, basés sur l'ID de l'utilisateur, pour garantir la confidentialité des documents.
    -   Gestion des Quotas :
        -   Permettre aux utilisateurs de stocker leur propre clé API de manière sécurisée (chiffrée en base de données).
        -   Modifier le llm-gateway pour qu'il transmette la clé de l'utilisateur au Proxy LiteLLM pour chaque requête.
        -   Ajouter une logique de limitation d'usage (ex: nombre de documents, nombre de requêtes par mois) pour chaque utilisateur.

-   **Mettre en place les Tests (`pytest`) :**
    -   Écrire les **tests unitaires** pour les fonctions critiques (utils, config, parsing des prompts).
    -   Écrire un **test d'intégration** simple pour l'endpoint `/health` et pour vérifier que l'agent route bien vers le bon "Tool".

-   **Construire la Pipeline de CI/CD (GitHub Actions) :**
    -   Mettre en place le workflow de **CI** qui exécute `lint` et les `tests` en parallèle pour chaque service.
    -   Préparer un squelette de workflow de **CD** pour le déploiement.

---

### **Phase 4 : Architecture de Déploiement et Cloud :**

*Objectif : Préparer et maîtriser le déploiement de l'application sur une infrastructure cloud scalable.*

-   **Passage au Stockage Cloud :**
    -   Remplacer le volume local /data par un bucket de stockage objet (ex: Cloudflare R2, Google Cloud Storage).
    -   Modifier l'UI et l'ingestion pour uploader/lire les fichiers depuis ce bucket.

-   **Héberger la Base de Données :**
    -   Migrer la base de données PostgreSQL vers un service managé (ex: Supabase, Cloud SQL).

-   **Préparation pour Kubernetes :**
    -   Installer et configurer **Kind** ou **Minikube**.
    -   Commencer à écrire les manifestes Kubernetes, en utilisant un Ingress Controller (Nginx) comme équivalent du reverse proxy.

---

#### **Phase 5 : Déploiement Cloud-Native sur Kubernetes**

*Objectif : Maîtriser le déploiement, la gestion d'environnements et l'automatisation de bout en bout.*


-   **Écrire les Manifestes complets :**
    -   Créer les fichiers `Deployment`, `Service`, `ConfigMap`, `Secret` pour chaque microservice.

-   **Gérer les Environnements (`staging` vs. `production`) :**
    -   Mettre en place **Kustomize** pour gérer les variations de configuration.

-   **Mettre à jour le Pipeline de CD (Déploiement Continu) :**
    -   Créer un workflow GitHub Actions pour le **Déploiement Continu**.
    -   Automatiser le déploiement sur **staging**.
    -   Mettre en place une **approbation manuelle** pour le déploiement en **production**.

-   **Porter ça sur GCP**

---

#### **Phase 6 : Expansion des Capacités de l'Agent**

*Objectif : Enrichir l'agent avec de nouvelles compétences et sources d'information.*

-   **Ajouter des Outils Externes :**
    -   Intégrer un outil **Web Search** (ex: `Tavily`).
    -   Outil de génération de document pdf.
    -   Outil de génération de présentation Google Slides.

-   **Diversifier les Sources de Données :**
    -   Ajouter l'ingestion depuis des URLs, Google Drive, Slack...
    -   gestion des images (**OCR** pour extraire le texte des images, description d'image etc.)

-   **Retrieval filtré :**
    -   Ingestion : Plusieurs vector store (1 par thème des doucments). Au moment de l'ingestion, appel LLM pour déterminer le thème du nouveau doc, si dispo parmis la liste -> ajout au vector store en question, sinon, création d'un nouveau. (Voir simplifier, sans appel LLM, un endpoint qui permet d'ingérer plusieurs documents dans un nouveau vector store avec thème donné manuellement, oui ça peut tout casser si le user fait n'importe quoi mais bon ce serait super utile pour moi.)
    -   Retrieval : Utiliser la requête du query expander (opti de coûts et de requêtes) pour demander de choisir le thème le plus pertinent pour la query parmis la liste de vector store dispo (si aucune alors connaissances du llm pour répondre) pour choisir dans quel vector store aller chercher l'info (gros gain de qualité de réponse potentiel si plusieurs documents sur sujets variés).
