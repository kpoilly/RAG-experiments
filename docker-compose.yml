services:
  cli:
    build:
      context: src/cli
    container_name: cli
    stdin_open: true
    tty: true
    environment:
      - API_URL=http://nginx/api
      - MAX_CONTEXT_TOKENS=${MAX_CONTEXT_TOKENS}
    depends_on:
      rag-core:
          condition: service_healthy
    networks:
      - rag_network

  streamlit-ui:
    build:
      context: src/streamlit_ui
    container_name: streamlit_ui
    restart: unless-stopped
    volumes:
      - ./data:/app/data
    environment:
      - API_URL=http://nginx/api
      - LLM_STRICT_RAG=${LLM_STRICT_RAG}
      - LLM_MODEL=${LLM_MODEL}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - RERANKER_MODEL=${RERANKER_MODEL}
      - RERANKER_THRESHOLD=${RERANKER_THRESHOLD}
    depends_on:
      rag-core:
          condition: service_healthy
    networks:
      - rag_network
    
  rag-core:
    build:
      context: src/rag_core
    container_name: rag_core
    restart: unless-stopped
    volumes:
      - ./data:/app/src/data
    environment:
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - DB_NAME=${DB_NAME}
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - COLLECTION_NAME=${COLLECTION_NAME}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - LLM_MODEL=${LLM_MODEL}
      - MAX_CONTEXT_TOKENS=${MAX_CONTEXT_TOKENS}
      - LLM_STRICT_RAG=${LLM_STRICT_RAG}
      - LLM_GATEWAY_URL=http://llm-gateway:8002
      - RERANKER_MODEL=${RERANKER_MODEL}
      - RERANKER_THRESHOLD=${RERANKER_THRESHOLD}
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2}
      - LANGCHAIN_ENDPOINT=${LANGCHAIN_ENDPOINT}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT}
    depends_on:
      - postgres
      - llm-gateway
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 30s
    networks:
      - rag_network
  
  llm-gateway:
    build:
      context: src/llm_gateway
    container_name: llm_gateway
    restart: unless-stopped
    environment:
      - LITELLM_PROXY_URL=http://litellm-proxy:8001
    depends_on:
      - litellm-proxy
    networks:
      - rag_network

  litellm-proxy:
    image: ghcr.io/berriai/litellm:v1.79.1-stable
    container_name: litellm_proxy
    ports:
      - "8003:8003"
    volumes:
      - ./deployments/litellm_proxy/litellm_config.yaml:/app/config.yaml
    environment:
      - GROQ_API_KEY=${GROQ_API_KEY}
    networks:
      - rag_network
    command: ["--config", "/app/config.yaml", "--port", "8001"]

  redis:
    image: redis:8.4-rc1-alpine3.22
    container_name: redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - rag_network

  postgres:
    image: ankane/pgvector:latest
    container_name: postgres_db
    restart: unless-stopped
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=${DB_NAME}
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    networks:
      - rag_network
  
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    restart: unless-stopped
    ports:
      - "8011:8011"
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@admin.com
      - PGADMIN_DEFAULT_PASSWORD=admin
    depends_on:
      - postgres

  nginx:
    image: nginx:1.29.3-alpine
    container_name: nginx
    restart: unless-stopped
    ports:
      - "80:80"
    volumes:
      - ./deployments/nginx/nginx.conf:/etc/nginx/conf.d/default.conf
    networks:
      - rag_network


volumes:
  postgres_data:
  redis_data:

networks:
  rag_network:
    driver: bridge
